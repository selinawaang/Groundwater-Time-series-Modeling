{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Prediction:\n",
    "- [In Progress:] model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data paths:\n",
    "feature_path = 'data/Germany/input_data.csv'\n",
    "target_path = 'data/Germany/heads.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for data preprocessing and feature engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(target_path, feature_path):\n",
    "    \n",
    "    '''\n",
    "    Function: reads in target and feature data into dataframes\n",
    "    \n",
    "    Arguments:\n",
    "        * target_path: path to target data\n",
    "        * feature path: path to feature data\n",
    "    \n",
    "    Return: \n",
    "        * df: dataframe combining feature and target data\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # read feature data\n",
    "    df_X = pd.read_csv(feature_path)\n",
    "    df_X = df_X.set_index('time')\n",
    "    df_X.index = pd.to_datetime(df_X.index)\n",
    "\n",
    "    # filter feature data for data within training period\n",
    "    df_X = df_X[(df_X.index>='2002-05-01' )& (df_X.index<='2016-12-31')]\n",
    "\n",
    "    # read target data\n",
    "    df_y = pd.read_csv(target_path)\n",
    "    df_y = df_y.set_index('Date')\n",
    "    df_y.index = pd.to_datetime(df_y.index)\n",
    "    df_y.index = df_y.index.rename('time')\n",
    "    df_y = df_y[(df_y.index>=df_X.index[0])]\n",
    "\n",
    "    df = pd.concat([df_X, df_y], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "### Feature Engineering:\n",
    "class engineer_features():\n",
    "    '''\n",
    "    Class to perform various types of feature engineering, new functions to be added\n",
    "    '''\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def year_signal(self):\n",
    "        timestamp_s = self.df.index.map(pd.Timestamp.timestamp)\n",
    "        day = 24*60*60\n",
    "        year = (365.2425)*day\n",
    "\n",
    "        self.df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "        self.df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))\n",
    "        \n",
    "        # visualize year signal:\n",
    "        plt.plot(np.array(df['Year sin'])[:300])\n",
    "        plt.plot(np.array(df['Year cos'])[:300])\n",
    "        plt.xlabel('Time [h]')\n",
    "        plt.title('Year signal')\n",
    "        plt.show()\n",
    "        \n",
    "    def lag_features(self, features):\n",
    "        # create lag feature\n",
    "        for j in features:\n",
    "            temps = pd.DataFrame(self.df[j].values)\n",
    "            shifted = temps.shift(1)\n",
    "            for k in lags:\n",
    "                window, means = {}, {}\n",
    "                window[\"{}\".format(k)] = shifted.rolling(window=k)\n",
    "                means[\"{}\".format(k)] = window[\"{}\".format(k)].mean()\n",
    "                self.df[\"{}_avg_{}\".format(j,k)]=means[\"{}\".format(k)].to_numpy()\n",
    "\n",
    "\n",
    "        # drop missing values after creating lag features\n",
    "        self.df.dropna(inplace = True)\n",
    "    \n",
    "def split(df, val_year, test_year):\n",
    "    '''\n",
    "    helper function to split dataset into train-val-test sets\n",
    "    '''\n",
    "    \n",
    "    train_df = df[df.index < val_year]\n",
    "    val_df = df[(df.index >= val_year) & (df.index < test_year)]\n",
    "    test_df = df[(df.index >= test_year)]\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "class Standardize():\n",
    "    def __init__(self, train_df, val_df, test_df, target_col):\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        self.train_mean = self.train_df.mean()\n",
    "        self.train_std = self.train_df.std()\n",
    "        self.target_col = target_col\n",
    "    \n",
    "    def scale(self):\n",
    "        self.train_df = (self.train_df - self.train_mean) / self.train_std\n",
    "        self.val_df = (self.val_df - self.train_mean) / self.train_std\n",
    "        self.test_df = (self.test_df - self.train_mean) / self.train_std\n",
    "        \n",
    "        return self.train_df, self.val_df, self.test_df\n",
    "        \n",
    "        \n",
    "    def reverse_scale_target(self, data):\n",
    "        reversed_data = data * self.train_std[self.target_col] + self.train_mean[self.target_col]\n",
    "        \n",
    "        return reversed_data\n",
    "        \n",
    "    \n",
    "def split_X_y(train_df, val_df, test_df):\n",
    "    \n",
    "    train_X_df = train_df.drop(columns = ['head'])\n",
    "    train_y_df = train_df['head']\n",
    "\n",
    "    val_X_df = val_df.drop(columns = ['head'])\n",
    "    val_y_df = val_df['head']\n",
    "\n",
    "    test_X_df = test_df.drop(columns = ['head'])\n",
    "    test_y_df = test_df['head']\n",
    "    \n",
    "    return train_X_df, train_y_df, val_X_df, val_y_df, test_X_df, test_y_df\n",
    "\n",
    "# reshape data for training and testing:\n",
    "def reshape_data(window_length, X, y, return_label_sequence = False):\n",
    "    '''\n",
    "    helper function to reshape data for lstm model\n",
    "    \n",
    "    Arguments:\n",
    "        * window_length: int\n",
    "            + number of time steps in each input sequence for lstm\n",
    "        * X: pd.DataFrame\n",
    "            + feature dataframe\n",
    "        * y: pd.DataFrame\n",
    "            + target dataframe\n",
    "        * return_label_sequence: bool\n",
    "            + if True, will perform rolling window on y for an LSTM model that predicts a sequence\n",
    "            + if False, will return y as a 1d tensor for an LSTM model that only predicts the final output\n",
    "    \n",
    "    Return:\n",
    "        * reshaped X\n",
    "        * reshaped y\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Define a list to hold the resulting tensors\n",
    "    X_tensors = []\n",
    "    y_tensors = []\n",
    "    \n",
    "    # Reshape X\n",
    "    for window in X.rolling(window=window_length):\n",
    "        # Extract the data from the window\n",
    "        window_data = window.values\n",
    "\n",
    "        # Check if the window has enough data points\n",
    "        if len(window_data) == window_length:\n",
    "            X_tensors.append(window_data)\n",
    "            \n",
    "    X_final_tensor = np.stack(X_tensors)\n",
    "    X_final_tensor = X_final_tensor.reshape(-1, window_length, X.shape[1])\n",
    "    \n",
    "    # Reshape y\n",
    "    \n",
    "    # if we want to return a sequence in LSTM, perform windowing on y\n",
    "    if return_label_sequence:\n",
    "        for window in y.rolling(window=window_length):\n",
    "            # Extract the data from the window\n",
    "            window_data = window.values\n",
    "\n",
    "            # Check if the window has enough data points\n",
    "            if len(window_data) == window_length:\n",
    "                y_tensors.append(window_data)\n",
    "        y_final_tensor = np.stack(y_tensors)\n",
    "    # if we don't want to return a sequence in LSTM, return y as a 1d array\n",
    "    else:\n",
    "        y_final_tensor = y[window_length-1:]\n",
    "\n",
    "    return tf.constant(X_final_tensor), tf.constant(y_final_tensor)\n",
    "\n",
    "\n",
    "# perform the entire splitting and preprocessing pipeline:\n",
    "def preprocessing_pipeline(df, \n",
    "                           val_year,\n",
    "                           test_year, \n",
    "                           window_length, \n",
    "                           scaling,\n",
    "                           target_col,\n",
    "                           return_sequence = None\n",
    "                          ):\n",
    "    '''\n",
    "    Function: performs splitting, scaling, reshaping and other preprocessing steps on data\n",
    "    \n",
    "    Arguments:\n",
    "        * df: pd.DataFrame\n",
    "            + dataframe containing target and feature data\n",
    "        * val_year: string\n",
    "            + split year between training and validation periods\n",
    "        * test_year: string\n",
    "            + split year between validation and testing periods\n",
    "        * window_length: int\n",
    "            + number of time steps in each input sequence for lstm\n",
    "        * scaling: object\n",
    "            + method of scaling data\n",
    "        * target_col: string\n",
    "            + name of target variable\n",
    "        * return_label_sequence: bool\n",
    "            + if True, will perform rolling window on y for an LSTM model that predicts a sequence\n",
    "            + if False, will return y as a 1d tensor for an LSTM model that only predicts the final output\n",
    "    Returns:\n",
    "        train_X, train_y, val_X, val_y, test_X, test_y\n",
    "    '''\n",
    "    \n",
    "    # perform splitting and standardizing\n",
    "    train_df, val_df, test_df = split(df, val_year, test_year)\n",
    "    \n",
    "    scale_method = scaling(train_df, val_df, test_df, target_col)\n",
    "    train_df, val_df, test_df = scale_method.scale()\n",
    "    \n",
    "    (train_X, train_y, val_X, val_y, test_X, test_y) = split_X_y(train_df, val_df, test_df)\n",
    "    \n",
    "    # reshape data\n",
    "    train_X, train_y = reshape_data(window_length, train_X, train_y, return_sequence)\n",
    "    val_X, val_y = reshape_data(window_length, val_X, val_y, return_sequence)\n",
    "    test_X, test_y = reshape_data(window_length, test_X, test_y, return_sequence)\n",
    "    \n",
    "    \n",
    "    return train_X, train_y, val_X, val_y, test_X, test_y, scale_method\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM model:\n",
    "def get_model(lstm_size, output_size = 1):     \n",
    "\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_size))\n",
    "    model.add(Dense(output_size))\n",
    "\n",
    "    \n",
    "    # train model\n",
    "    model.compile(loss='mse', \n",
    "                  optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# plot history\n",
    "def plot_training_history(history):\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def visualize_prediction(pred, true):\n",
    "\n",
    "    plt.plot(pred, label = \"prediction\")\n",
    "    plt.plot(true, label = \"true\")\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('head')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "mean_squared_error(y_pred, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and preprocess data\n",
    "df = read_data(target_path, feature_path)\n",
    "lstm_ft_eng = engineer_features(df)\n",
    "lstm_ft_eng.year_signal()\n",
    "df = lstm_ft_eng.df\n",
    "\n",
    "# create train-val-test data\n",
    "train_X, train_y, val_X, val_y, test_X, test_y, scale_method = preprocessing_pipeline(df, '2015','2016', 30, Standardize, 'head')\n",
    "\n",
    "# fit model:\n",
    "lstm_model = get_model(50,1)\n",
    "\n",
    "history = model.fit(train_X, \n",
    "                    train_y, \n",
    "                    epochs=50, \n",
    "                    batch_size=10, \n",
    "                    validation_data=(val_X, val_y), \n",
    "                    verbose=2, \n",
    "                    shuffle=False)\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "# evaluate model on test set:\n",
    "y_pred = model.predict(test_X)\n",
    "y_pred = scale_method.reverse_scale_target(y_pred)\n",
    "test_y = scale_method.reverse_scale_target(test_y)\n",
    "final_score = mean_squared_error(y_pred, test_y)\n",
    "\n",
    "# visualize results on training, validation and test:\n",
    "visualize_prediction(y_pred, test_y)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
